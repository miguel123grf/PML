{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOmo1a6QqttysjQy7Ru45eT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ZamTWGvdbjd","executionInfo":{"status":"ok","timestamp":1715880923910,"user_tz":-60,"elapsed":205023,"user":{"displayName":"Miguel Gonçalves Ferreira","userId":"13987281937396337409"}},"outputId":"e2f970d0-5c1f-4c50-f3c5-025219fb266a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 170498071/170498071 [00:02<00:00, 84985738.61it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n","Epoch 1, Batch 100, Loss: 1.748\n","Epoch 2, Batch 100, Loss: 1.317\n","Epoch 3, Batch 100, Loss: 1.171\n","Epoch 4, Batch 100, Loss: 1.078\n","Epoch 5, Batch 100, Loss: 1.008\n","Finished Training\n","Accuracy on the test set: 63.90%\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","import matplotlib.pyplot as plt\n","\n","# Define a CNN model\n","class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n","        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.fc1 = nn.Linear(32 * 8 * 8, 128)\n","        self.fc2 = nn.Linear(128, 10)\n","\n","    def forward(self, x):\n","        x = self.pool(torch.relu(self.conv1(x)))\n","        x = self.pool(torch.relu(self.conv2(x)))\n","        x = x.view(-1, 32 * 8 * 8)\n","        x = torch.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x\n","\n","# Data preprocessing and augmentation\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","# Download CIFAR-10 dataset and create data loaders\n","trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n","trainloader = DataLoader(trainset, batch_size=256, shuffle=True)\n","\n","testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n","testloader = DataLoader(testset, batch_size=256, shuffle=False)\n","\n","# Initialize the model, loss function, and optimizer\n","model = CNN()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Training loop\n","num_epochs = 5\n","for epoch in range(num_epochs):\n","    running_loss = 0.0\n","    for i, data in enumerate(trainloader, 0):\n","        inputs, labels = data\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","        if i % 100 == 99:\n","            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100:.3f}')\n","            running_loss = 0.0\n","\n","print('Finished Training')\n","\n","# Evaluate the model on the test set\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data in testloader:\n","        inputs, labels = data\n","        outputs = model(inputs)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print(f'Accuracy on the test set: {100 * correct / total:.2f}%')\n"]},{"cell_type":"markdown","source":["Código da Aula\n"],"metadata":{"id":"dj8lzioWgnKL"}},{"cell_type":"code","source":["#@title Script that implements a convolutional neural network with PyTorch over the mnist 8 by 8 practice data set\n","# code adapted from https://github.com/rasbt/machine-learning-book/blob/main/ch14/ch14_part1.py\n","\n","'''\n","This code does the following:\n","    Splits the dataset into training and testing sets.\n","    Standardizes the features using StandardScaler.\n","    Reshapes dataset to fit the model\n","    Instantiates the model (CNN)\n","    Defines the loss function (Cross Entropy Loss) and optimizer (Adam).\n","    Trains the model for num_epochs epochs.\n","    Tests the trained model on the test set and evaluates the accuracy.\n","'''\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchsummary import summary\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.datasets import  load_digits\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import ConfusionMatrixDisplay\n","import matplotlib.pyplot as plt\n","import random\n","import numpy as np\n","\n","################################################################################ Data and parameters\n","SHOW=False # plot some digit for mnist 8*8\n","\n","examples = load_digits() # https://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html; 10 digits;  1797 examples\n","if SHOW:\n","    idx=random.randint(0,len(examples.target))\n","    print(examples.data[idx])\n","    print(examples.data[idx].reshape(8,8))\n","    print(examples.target[idx])\n","    plt.matshow(examples.data[idx].reshape(8,8), cmap=plt.cm.gray_r)\n","    plt.show()\n","\n","X = examples.data # np.ndarray (1797, 64)\n","y = examples.target # (1797,)\n","\n","# parameter constants\n","test_size=0.2\n","hidden_size = 8\n","batch_size= 256\n","num_epochs = 50\n","# Optimizer specific options\n","learning_rate=0.1\n","regularization_param=0.001\n","# Dropout: if p>0\n","dropout_p=0.1 # During training, randomly zeroes some of the elements of the input tensor with probability p.\n","\n","########################################################################### train and test, pre-processing\n","# Splitting data into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n","\n","# Standardize features\n","scaler = StandardScaler()\n","print(X_train.shape)\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","# mnist data set has examples with 64 attributes\n","# We need to reshape that information into NCHW (batch size, channels, height, width)\n","def reshape_mnist(X,W,H):\n","    X=X.reshape((X.shape[0],W,H))\n","    return np.expand_dims(X,1) # one channel\n","\n","# Convert numpy arrays to PyTorch tensors of the right shape (labels do not need to be reshaped)\n","X_train_tensor = torch.tensor(reshape_mnist(X_train,8,8), dtype=torch.float32)\n","X_test_tensor = torch.tensor(reshape_mnist(X_test,8,8), dtype=torch.float32)\n","y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n","y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n","print('Number of examples in training set:',X_train_tensor.shape)\n","print('Number of examples in test set:', X_test_tensor.shape)\n","\n","# Instantiate the model\n","input_size = X_train_tensor.shape[1]\n","output_size = len(examples.target_names)\n","\n","# Create dataloader and determine batch size (note: batchsize is the first parameter in NCHW)\n","train_dl=DataLoader(TensorDataset(X_train_tensor,y_train_tensor), batch_size, shuffle=True)\n","test_dl=DataLoader(TensorDataset(X_test_tensor,y_test_tensor), batch_size, shuffle=True)\n","\n","if SHOW:\n","    class_names = [str(i) for i in range(10)]\n","    # Plot the images\n","    plt.figure(figsize=(10, 5))\n","    image_count = 0\n","    for images, labels in train_dl:\n","        for i in range(len(images)):\n","            plt.subplot(4, 5, image_count + 1)\n","            plt.imshow(np.transpose(images[i], (1, 2, 0)), cmap=\"gray\")\n","            plt.title(class_names[labels[i]])\n","            plt.axis('off')\n","            image_count += 1\n","            if image_count >= 20:\n","                break\n","        if image_count >= 20:\n","            break\n","    plt.show()\n","\n","###################################################################################### CNN  model\n","model=nn.Sequential(\n","    nn.Conv2d(in_channels=1,out_channels=8,kernel_size=3,padding=1),\n","    nn.ReLU(),\n","    nn.MaxPool2d(kernel_size=2),\n","    nn.Flatten(),\n","    nn.Linear(8*4*4, hidden_size),\n","    nn.BatchNorm1d(hidden_size),\n","    nn.ReLU(),\n","    nn.Linear(hidden_size, hidden_size),\n","    nn.BatchNorm1d(hidden_size),\n","    nn.ReLU(),\n","    nn.Dropout(p=dropout_p),\n","    nn.Linear(hidden_size, output_size)\n",")\n","\n","'''\n","Compare with NN from previous script:\n","model=nn.Sequential(\n","    nn.Linear(input_size, hidden_size),\n","    nn.BatchNorm1d(hidden_size),\n","    nn.ReLU(),\n","    nn.Dropout(p=dropout_p),\n","    nn.Linear(hidden_size, hidden_size),\n","    nn.BatchNorm1d(hidden_size),\n","    nn.ReLU(),\n","    nn.Dropout(p=dropout_p),\n","    nn.Linear(hidden_size, output_size)\n",")\n","'''\n","# model description\n","summary(model,(1,8,8)) # C, H, W\n","\n","# Define loss function and optimizer\n","# Either torch.nn.NLLLoss or torch.nn.CrossEntropyLoss can be used: CrossEntropyLoss (https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) implements softmax internally\n","loss_fn = nn.CrossEntropyLoss()\n","\n","# Optimizer: optimizer object that will hold the current state and will update the parameters based on the computed gradients\n","# for param in model.parameters(): print(param.data)\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=regularization_param)\n","\n","# Train the model and predict on test samples to estimate accuracy\n","# history stores losses, accuracy, actual labels and predictions\n","history = train(model, optimizer, loss_fn, num_epochs, train_dl, test_dl)\n","\n","# plot losses along epochs\n","plot_losses(history)\n","# plot confusion matrix\n","plot_accuracy_from_predictions(history)\n","#plot_accuracy(hist)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":697},"id":"E0p2UqjVgryD","executionInfo":{"status":"error","timestamp":1715881569559,"user_tz":-60,"elapsed":3411,"user":{"displayName":"Miguel Gonçalves Ferreira","userId":"13987281937396337409"}},"outputId":"9b9e2c7b-7636-440a-e025-c0873dc4fc5e"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["(1437, 64)\n","Number of examples in training set: torch.Size([1437, 1, 8, 8])\n","Number of examples in test set: torch.Size([360, 1, 8, 8])\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1              [-1, 8, 8, 8]              80\n","              ReLU-2              [-1, 8, 8, 8]               0\n","         MaxPool2d-3              [-1, 8, 4, 4]               0\n","           Flatten-4                  [-1, 128]               0\n","            Linear-5                    [-1, 8]           1,032\n","       BatchNorm1d-6                    [-1, 8]              16\n","              ReLU-7                    [-1, 8]               0\n","            Linear-8                    [-1, 8]              72\n","       BatchNorm1d-9                    [-1, 8]              16\n","             ReLU-10                    [-1, 8]               0\n","          Dropout-11                    [-1, 8]               0\n","           Linear-12                   [-1, 10]              90\n","================================================================\n","Total params: 1,306\n","Trainable params: 1,306\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.01\n","Params size (MB): 0.00\n","Estimated Total Size (MB): 0.02\n","----------------------------------------------------------------\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'train' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-d43af393914c>\u001b[0m in \u001b[0;36m<cell line: 147>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;31m# Train the model and predict on test samples to estimate accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;31m# history stores losses, accuracy, actual labels and predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;31m# plot losses along epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"]}]}]}